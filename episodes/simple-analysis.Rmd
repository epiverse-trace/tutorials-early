---
title: 'Simple analysis'
teaching: 20
exercises: 10
---

:::::::::::::::::::::::::::::::::::::: questions 

- What is the growth rate of the epidemic?
- How to identify the peak time of an outbreak?
- How to compute moving average of cases?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Perform an early analysis of outbreak data
- Identify trends, exponential, doubling, and peak time

::::::::::::::::::::::::::::::::::::::::::::::::

## Introduction

Understanding trends in surveillance data is crucial for understanding epidemic drivers and dynamics. This may include forecasting disease burden, planning future public health interventions, and assessing the effectiveness of past control measures. By analyzing trends, policymakers and public health experts can make informed decisions to mitigate the spread of diseases and protect public health. This episode focuses on how to perform a simple early analysis on incidence data. It uses the same dataset of **Covid-19 case data from England** that utilized it in [Aggregate and visualize](../episodes/describe-cases.Rmd) episode. 

::::::::::::::::::: checklist

### The double-colon

The double-colon `::` in R let you call a specific function from a package without loading the entire package into the current environment. 

For example, `dplyr::filter(data, condition)` uses `filter()` from the `{dplyr}` package.

This help us remember package functions and avoid namespace conflicts.

:::::::::::::::::::


## Simple model

Aggregated case data over specific time units (i.e. incidence data), typically represent the number of cases that occur within that time frame. We can think of these cases as noisy observations generated by the underlying epidemic process (which we cannot directly observe). To account for randomness in the observations, we can assume that observed cases follow either `Poisson distribution` (if cases are reported at a constant average rate over time) or a `negative binomial (NB) distribution` (if there is potential variability in reporting over time). When analyzing such data, one common approach is to examine the trend over time by computing the rate of change, which can indicate whether there is exponential growth or decay in the number of cases. Exponential growth implies that the number of cases is increasing at an accelerating rate over time, while exponential decay suggests that the number of cases is decreasing at a decelerating rate.

The `i2extras` package provides methods for modelling the trend in case data, calculating moving averages, and exponential growth or decay rate. The code chunk below computes the Covid-19 trend in UK within first 3 months using negative binomial distribution. 


```{r, warning=FALSE, message=FALSE}
# load packages which provides methods for modeling
library(i2extras)
library(incidence2)

# read data from {outbreaks} package
covid19_eng_case_data <- outbreaks::covid19_england_nhscalls_2020

# subset the covid19_eng_case_data to include only the first 3 months of data
df <- base::subset(
  covid19_eng_case_data,
  covid19_eng_case_data$date <= min(covid19_eng_case_data$date) + 90
)

# uses the incidence function from the incidence2 package to compute the
# incidence data
df_incid <- incidence2::incidence(
  df,
  date_index = "date",
  groups = "sex"
)

# fit a curve to the incidence data. The model chosen is the negative binomial
# distribution with a significance level (alpha) of 0.05.
fitted_curve_nb <-
  i2extras::fit_curve(
    df_incid,
    model = "negbin",
    alpha = 0.05
  )

# plot fitted curve
base::plot(fitted_curve_nb, angle = 45) +
  ggplot2::labs(x = "Date", y = "Cases")
```


::::::::::::::::::::::::::::::::::::: challenge 

## Challenge 1: Poisson distribution

Repeat the above analysis using Poisson distribution.

:::::::::::::::::::::::: solution 

```{r, warning=FALSE, message=FALSE}
fitted_curve_poisson <-
  i2extras::fit_curve(
    x = df_incid,
    model = "poisson",
    alpha = 0.05
  )

base::plot(fitted_curve_poisson, angle = 45) +
  ggplot2::labs(x = "Date", y = "Cases")
```

:::::::::::::::::::::::::::::::::
::::::::::::::::::::::::::::::::::::::::::::::::

## Exponential growth or decay rate

The exponential growth or decay rate, denoted as $r$, serves as an indicator for the trend in cases, indicating whether they are increasing (growth) or decreasing (decay) on an exponential scale. This rate is computed using the so-called  **renewal equation** [(Wallinga et al. 2006)](https://royalsocietypublishing.org/doi/10.1098/rspb.2006.3754), which mechanistically links the reproductive number $R$ of new cases (i.e. the average number of people that a typical case infects) to the generation interval of the disease (i.e. the average delay from one infection to the next in a chain of transmission). This computational method is implemented in the `{i2extras}` package.

Below is a code snippet demonstrating how to extract the growth/decay rate from the above **negative binomial**-fitted  curve using the `growth_rate()` function:

```{r, message=FALSE, warning=FALSE}
rates_nb <- i2extras::growth_rate(fitted_curve_nb)
rates_nb <- base::as.data.frame(rates_nb) |>
  subset(select = c(sex, r, r_lower, r_upper))
base::print(rates_nb)
```


::::::::::::::::::::::::::::::::::::: challenge 

## Challenge 2:  Growth rates from a **Poisson**-fitted curve

Extract growth rates from the **Poisson**-fitted curve of **Challenge 1**?

::::::::::::::::::::::::::::::::::::::::::::::::

## Peak time

The **peak time** is the time at which the highest number of cases is observed in the aggregated data. It can be estimated using the `i2extras::estimate_peak()` function as shown in the below code chunk, which identify peak time from the `incidenc2` object `df_incid`.

```{r, message=FALSE, warning=FALSE}
peaks_nb <- i2extras::estimate_peak(df_incid, progress = FALSE) |>
  subset(select = -c(count_variable, bootstrap_peaks))

base::print(peaks_nb)
```


## Moving average

A moving or rolling average calculates the average number of cases within a specified time period. This can be achieved by utilizing the `add_rolling_average()` function from the `{i2extras}` package on an `incidence2 object`. The following code chunk demonstrates the computation of the weekly average number of cases from the `incidence2` object `df_incid`, followed by visualization.

```{r, warning=FALSE, message=FALSE}
library(ggplot2)

moving_Avg_week <- i2extras::add_rolling_average(df_incid, n = 7L)

base::plot(moving_Avg_week, border_colour = "white", angle = 45) +
  ggplot2::geom_line(
    ggplot2::aes(
      x = date_index,
      y = rolling_average,
      color = "red"
    )
  ) +
  ggplot2::labs(x = "Date", y = "Cases")
```

::::::::::::::::::::::::::::::::::::: challenge 

## Challenge 3: Monthly moving average

Compute and visualize the monthly moving average of cases on `df_incid`? 

:::::::::::::::::::::::: solution 

```{r, warning=FALSE, message=FALSE}
moving_Avg_mont <- i2extras::add_rolling_average(df_incid, n = 30L)

base::plot(
  moving_Avg_mont,
  border_colour = "white",
  angle = 45
) +
  ggplot2::geom_line(
    ggplot2::aes(
      x = date_index,
      y = rolling_average,
      color = "red"
    )
  ) +
  ggplot2::labs(x = "Date", y = "Cases")
```

:::::::::::::::::::::::::::::::::
::::::::::::::::::::::::::::::::::::::::::::::::


::::::::::::::::::::::::::::::::::::: keypoints 

- Use `{i2extras}` to:
  - fit epi-curve using either **Poisson** or **negative binomial** distributions,  
  - calculate exponential growth or decline of cases, 
  - find peak time, and 
  - computing moving average of cases in specified time window.

::::::::::::::::::::::::::::::::::::::::::::::::

