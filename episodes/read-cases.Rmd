---
title: 'Read case data'
teaching: 20
exercises: 10
editor_options: 
  chunk_output_type: inline
---

:::::::::::::::::::::::::::::::::::::: questions 

- Where do you usually store your outbreak data?
- How many different data formats can I read? 
- Is it possible to import data from databases and health APIs? 
::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Explain how to import outbreak data from different sources into `R` 
environment.
::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: prereq

## Prerequisites

This episode requires you to be familiar with:

**Data science** : Basic programming with R.
:::::::::::::::::::::::::::::::::

## Introduction

The initial step in outbreak analysis involves importing the target dataset into the `R` environment from various sources. Outbreak data is typically stored in files of diverse formats, relational database management systems (RDBMS), or health information system (HIS) application program interfaces (APIs) such as [REDCap](https://www.project-redcap.org/), [DHIS2](https://dhis2.org/), etc. The latter  option is particularly well-suited for storing institutional health data. This episode will elucidate the process of reading cases from these sources.

Let's start by loading the package `{rio}` to read data and the package `{here}` to easily find a file path within your RStudio project. We'll use the pipe `%>%` to connect some of their functions, including others from the package `{dplyr}`, so let's also call to the tidyverse package:

```{r,eval=TRUE,message=FALSE,warning=FALSE}
# Load packages
library(tidyverse) # for {dplyr} functions and the pipe %>%
library(rio) # for importing data
library(here) # for easy file referencing
```

::::::::::::::::::: checklist

### The double-colon

The double-colon `::` in R let you call a specific function from a package without loading the entire package into the current environment. 

For example, `dplyr::filter(data, condition)` uses `filter()` from the `{dplyr}` package.

This help us remember package functions and avoid namespace conflicts.

:::::::::::::::::::


:::::::::: prereq

### Setup a project and folder

- Create an RStudio project. If needed, follow this [how-to guide on "Hello RStudio Projects"](https://docs.posit.co/ide/user/ide/get-started/#hello-rstudio-projects) to create one.
- Inside the RStudio project, create the `data/` folder.
- Inside the `data/` folder, save the [ebola_cases.csv](https://epiverse-trace.github.io/tutorials-early/data/ebola_cases.csv) and [marburg.zip](https://epiverse-trace.github.io/tutorials-early/data/Marburg.zip) files.

::::::::::

## Reading from files 

Several packages are available for importing outbreak data stored in individual files into `R`. These include [rio](https://gesistsa.github.io/rio/), [readr](https://readr.tidyverse.org/) from the `tidyverse`, [io](https://bitbucket.org/djhshih/io/src/master/), [ImportExport](https://cran.r-project.org/web/packages/ImportExport/index.html), and [data.table](https://rdatatable.gitlab.io/data.table/). Together, these packages offer methods to read single or multiple files in a wide range of formats.

The below example shows how to import a `csv` file into `R` environment using `{rio}` package.

```{r,eval=FALSE,echo=TRUE}
# read data
# e.g., the path to our file is data/raw-data/ebola_cases.csv then:
ebola_confirmed <- rio::import(
  here::here("data", "ebola_cases.csv")
) %>%
  dplyr::as_tibble() # for a simple data frame output

# preview data
ebola_confirmed
```


```{r,eval=TRUE, echo=FALSE, message=FALSE}
# internal for DBI::dbWriteTable()
# read data
ebola_confirmed <- rio::import(
  file.path("data", "ebola_cases.csv")
) %>%
  dplyr::as_tibble() # for a simple data frame output
```

Similarly, you can import files of other formats such as `tsv`, `xlsx`, ... etc.

::::::::::::::::::::::::::::::::: challenge

###  Reading compressed data 

Take 1 minute:
Can you read data from a compressed file in `R`? Download this [zip file](https://epiverse-trace.github.io/tutorials-early/data/Marburg.zip) containing data for Marburg outbreak and then import it to your working environment.

::::::::::::::::: hint

You can check the [full list of supported file formats](https://gesistsa.github.io/rio/#supported-file-formats) 
in the `{rio}` package on the package website. To expand {rio} to the full range of support for import and export formats run:


```{r, eval=FALSE}
rio::install_formats()
```

You can use this template to read the file: 

`rio::import(here::here("some", "where", "downto", "path", "file_name.zip"))`

::::::::::::::::::::::

::::::::::::::::: solution

```{r,eval=FALSE}
rio::import(here::here("data", "Marburg.zip"))
```
::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::::::::


## Reading from databases

The [DBI](https://dbi.r-dbi.org/) package serves as a versatile interface for interacting with database management 
systems (DBMS) across different back-ends or servers. It offers a uniform method for accessing and retrieving data from various database systems.


The following code chunk demonstrates how to create a temporary SQLite database in memory, store the `ebola_confirmed` as a table on it, and subsequently read it:

```{r,warning=FALSE,message=FALSE}
library(DBI)
library(RSQLite)

# Create a temporary SQLite database in memory
db_con <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  dbname = ":memory:"
)

# Store the 'ebola_confirmed' dataframe as a table named 'cases'
# in the SQLite database
DBI::dbWriteTable(
  conn = db_con,
  name = "cases",
  value = ebola_confirmed
)

# Read data from the 'cases' table
result <- DBI::dbReadTable(
  conn = db_con,
  name = "cases"
)

# Close the database connection
DBI::dbDisconnect(conn = db_con)

# View the result
result %>%
  dplyr::as_tibble() # for a simple data frame output
```

This code first establishes a connection to an SQLite database created in memory using `dbConnect()`. Then, it writes the `ebola_confirmed` into a table named 'cases' within the database using the `dbWriteTable()` function. Subsequently, it reads the data from the 'cases' table using `dbReadTable()`. Finally, it closes the database connection with `dbDisconnect()`.

:::::::::::::::::::::: callout

### Run SQL queries in R using dbplyr

We can use database interface packages to optimize memory usage. If we process the database with "queries" (e.g., select, filter, summarise) before extraction, we can reduce the memory load in our RStudio session. Conversely, conducting all data manipulation outside the database management system can lead to occupying more disk space than desired running out of memory.

Read this [tutorial episode on SQL databases and R](https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html#complex-database-queries) to practice how to make relational database SQL queries using multiple {dplyr} verbs like `left_join()` among tables before pulling down data to your local session with `collect()`!

::::::::::::::::::::::


## Reading from HIS APIs

Health related data are also increasingly stored in specialized HIS APIs like **Fingertips**, **GoData**, **REDCap**, and **DHIS2**. In such case one can resort to [readepi](https://epiverse-trace.github.io/readepi/) package, which enables reading  data from HIS-APIs.  
-[TBC]

::::::::::::::::::::::::::::::::::::: keypoints 
- Use `{rio}, {io}, {readr}` and `{ImportExport}` to read data from individual files.
- Use `{readepi}` to read data form HIS APIs and RDBMS.
::::::::::::::::::::::::::::::::::::::::::::::::
