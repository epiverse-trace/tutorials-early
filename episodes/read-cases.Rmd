---
title: 'Read case data'
teaching: 20
exercises: 10
editor_options: 
  chunk_output_type: inline
---

:::::::::::::::::::::::::::::::::::::: questions 

- Where do you usually store your outbreak data?
- What data formats do you use for analysis? 
- Can you import data from databases and Health Information Systems (HIS) through their APIs? 
::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Explain how to import outbreak data from different sources into `R` 
environment.
::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: prereq

## Prerequisites

This episode requires you to be familiar with:

**Data science** : Basic tasks with R.
:::::::::::::::::::::::::::::::::

## Introduction

The initial step in outbreak analysis typically involves importing the target dataset into the `R` environment from either a local source (like a file on your computer) or external source (like a database). Outbreak data can be stored in diverse formats, relational database management systems (RDBMS), or health information systems (HIS), such as [REDCap](https://www.project-redcap.org/) and [DHIS2](https://dhis2.org/), which provide application program interfaces (APIs) to the system's database  so verified users can easily add and fetch data entries. The latter option is particularly well-suited for collecting and storing large-scale institutional health data. This episode will elucidate the process of reading cases from these sources.

Let's start by loading the `{rio}` package to read data and the `{here}` package to easily find a file path within your RStudio project. We'll use the pipe `%>%` operator from the `{magrittr}` package to easily connect some of their functions, including functions from the data formatting package `{dplyr}`. We'll therefore call the `{tidyverse}` package, which includes both `{magrittr}` and `{dplyr}`.

```{r,eval=TRUE,message=FALSE,warning=FALSE}
# Load packages
library(tidyverse) # for {dplyr} functions and the pipe %>%
library(rio) # for importing data
library(here) # for easy file referencing
```

::::::::::::::::::: checklist

### The double-colon (`::`) operator

The `::` in R lets you access functions or objects from a specific package without attaching the entire package to the search path. It offers several important
advantages including the followings:

* Telling explicitly which package a function comes from, reducing ambiguity and potential conflicts when several packages have functions with the same name.
* Allowing to call a function from a package without loading the whole package
with library().

For example, the command `dplyr::filter(data, condition)` means we are calling
the `filter()` function from the `{dplyr}` package.

:::::::::::::::::::


:::::::::: prereq

### Setup a project and folder

- Create an RStudio project. If needed, follow this [how-to guide on "Hello RStudio Projects"](https://docs.posit.co/ide/user/ide/get-started/#hello-rstudio-projects) to create one.
- Inside the RStudio project, create a `data/` folder.
- Inside the `data/` folder, save the [ebola_cases_2.csv](https://epiverse-trace.github.io/tutorials-early/data/ebola_cases_2.csv) and [marburg.zip](https://epiverse-trace.github.io/tutorials-early/data/Marburg.zip) CSV files.

::::::::::

## Reading from files 

Several packages are available for importing outbreak data stored in individual files into `R`. These include [{rio}](https://gesistsa.github.io/rio/), [{readr}](https://readr.tidyverse.org/) from the `{tidyverse}`, [{io}](https://bitbucket.org/djhshih/io/src/master/), [{ImportExport}](https://cran.r-project.org/web/packages/ImportExport/index.html), [{data.table}](https://rdatatable.gitlab.io/data.table/), and similar functions from the {base} R package. Together, these packages offer methods to read single or multiple files in a wide range of formats.

The below example shows how to import a `csv` file into `R` environment using `{rio}` package. We use the `{here}` package to tell R to look for the file in the `data/` folder of your project, and `as_tibble()` to convert it into a tidier format for subsequent analysis in R.

```{r,eval=FALSE,echo=TRUE}
# read data
# e.g., if the path to our file is "data/raw-data/ebola_cases_2.csv" then:
ebola_confirmed <- rio::import(
  here::here("data", "raw-data", "ebola_cases_2.csv")
) %>%
  dplyr::as_tibble() # for a simple data frame output

# preview data
ebola_confirmed
```


```{r,eval=TRUE, echo=FALSE, message=FALSE}
# read data
ebola_confirmed <- rio::import(
  file.path("data", "ebola_cases_2.csv")
) %>%
  dplyr::as_tibble() # for a simple data frame output

# preview data
ebola_confirmed
```

Similarly, you can import files of other formats such as `tsv`, `xlsx`, ... etc
using the same function.

:::::::::::::::::::: checklist

### Why should we use the {here} package?

The `{here}` package is designed to simplify file referencing in R projects by providing a reliable way to construct file paths relative to the project root. The main reason to use it is to ensure **Cross-Environment Compatibility**.

It works across different operating systems (Windows, Mac, Linux) without needing to adjust file paths. 

- On Windows, paths are written using backslashes ( `\` ) as the separator between folder names: `"data\raw-data\file.csv"` 
- On Unix based operating system such as macOS or Linux the forward slash ( `/` ) is used as separator between folder names: `"data/raw-data/file.csv"`

The `{here}` package is ideal for adding one more layer of reproducibility to your work. If you are interested in reproducibility, we invite you to [read this tutorial to increase the openess, sustainability, and reproducibility of your epidemic analysis with R](https://epiverse-trace.github.io/research-compendium/)

::::::::::::::::::::

::::::::::::::::::::::::::::::::: challenge

###  Reading compressed data 

Take 1 minute:
Can you read data from a compressed file in `R`? Download this [zip file](https://epiverse-trace.github.io/tutorials-early/data/Marburg.zip) containing data for Marburg outbreak and then import it to your working environment.

::::::::::::::::: hint

You can check the [full list of supported file formats](https://gesistsa.github.io/rio/#supported-file-formats) 
from the `{rio}` package website. To expand {rio} to its current unsupported file formats, run:


```{r, eval=FALSE}
rio::install_formats()
```

You can use this example to read the file: 

`rio::import(here::here("some", "where", "downto", "path", "file_name.zip"))`

::::::::::::::::::::::

::::::::::::::::: solution

```{r,eval=FALSE}
rio::import(here::here("data", "Marburg.zip"))
```
::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::::::::


## Reading from databases

The [{DBI}](https://dbi.r-dbi.org/) package serves as a versatile interface for interacting with relational database management systems (DBMS) across different back-ends or servers. It offers a uniform method for accessing and retrieving data from various database systems.

::::::::::::: discussion

### Advantages of reading data directly from a database?

We can use database interface packages to optimize the amount of memory used during our R session. If we query the database with data filtration requests (e.g., select, filter, summarise) before extraction, we can reduce the memory load in our RStudio session. Conversely, conducting all data manipulation outside the database management system by loading the full dataset into R can use up much more computer memory (i.e. RAM) than is feasible on a local machine, which can lead RStudio to slow down or even freeze.

Relational database management systems (RDBMS) also have the advantage that multiple users can access, store and analyse parts of the dataset simultaneously, without having to transfer individual files, which would make it very difficult to track which version is up-to-date.

:::::::::::::

The following code chunk demonstrates in four steps how to create a SQLite database in memory, store the `ebola_confirmed` as a table on it, and subsequently read it.

### 1. Connection to the a database

We first need to establish a connection to an SQLite database created on our machine and stored in its local memory with `DBI::dbConnect()`. 

```{r,warning=FALSE,message=FALSE}
library(DBI)
library(RSQLite)

# Create a SQLite database in memory
db_connection <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  dbname = ":memory:"
)
```

::::::::::::::::: callout

A real-life connection to an external SQLite database would look like this:

```{r, eval=FALSE}
# in real-life
db_connection <- DBI::dbConnect(
  RSQLite::SQLite(), 
  host = "database.epiversetrace.com",
  user = "juanito",
  password = epiversetrace::askForPassword("Database password")
)
```

:::::::::::::::::

### 2. Create a table in the database from a data frame

After establishing the connection with the database, we can now write out the `ebola_confirmed` data frame into a table named `cases` within the database using the `DBI::dbWriteTable()` function.

```{r,warning=FALSE,message=FALSE}
# Store the 'ebola_confirmed' data frame as a table named 'cases'
# in the SQLite database
DBI::dbWriteTable(
  conn = db_connection,
  name = "cases",
  value = ebola_confirmed
)
```

In a relational database framework, you can have more than one table. Each table can belong to a specific `entity` (e.g., patients, care units, jobs). All tables will be related by a common ID or `primary key`.

### 3. Read data from a table in a database

<!-- Subsequently, we reads the data from the `cases` table using `DBI::dbReadTable()`. -->

<!-- ```{r,warning=FALSE,message=FALSE} -->
<!-- # Read data from the 'cases' table -->
<!-- extracted_data <- DBI::dbReadTable( -->
<!--   conn = db_connection, -->
<!--   name = "cases" -->
<!-- ) -->
<!-- ``` -->

We can reads the data from the `cases` table using `dplyr::tbl()`.

```{r}
# Read one table from the database
mytable_db <- dplyr::tbl(src = db_connection, "cases")
```

If we apply `{dplyr}` verbs to this table of a SQLite database, these verbs will be translated to an SQL queries.

```{r}
# Show the translated SQL queries 
mytable_db %>%
  dplyr::filter(confirm > 50) %>%
  dplyr::arrange(desc(confirm)) %>%
  dplyr::show_query()
```

### 4. Extract data from the database

Use `dplyr::collect()` to force computation of a database query and extract the output to your local computer.

```{r}
# Pull all data down to a local tibble
extracted_data <- mytable_db %>%
  dplyr::filter(confirm > 50) %>%
  dplyr::arrange(desc(confirm)) %>%
  dplyr::collect()
```

The `extracted_data` object represents the extracted data, ideally after applying the specified queries that reduces its size.

```{r,warning=FALSE,message=FALSE}
# View the extracted_data
extracted_data
```

:::::::::::::::::::::: callout

### Run SQL queries in R using {dbplyr}

Practice how to make relational database SQL queries using multiple `{dplyr}` verbs like `dplyr::left_join()` among tables before pulling out data to your local session with `dplyr::collect()`! 

You can also review the `{dbplyr}` R package. But for a step-by-step tutorial about SQL, we recommend you this [tutorial about data management with SQL for Ecologist](https://datacarpentry.org/sql-ecology-lesson/).

::::::::::::::::::::::


### 5. Close the database connection

Finally, we can close the database connection with `dbDisconnect()`.

```{r,warning=FALSE,message=FALSE}
# Close the database connection
DBI::dbDisconnect(conn = db_connection)
```

## Reading from HIS APIs

Health related data are also increasingly stored in specialized HIS APIs like **Fingertips**, **GoData**, **REDCap**, and **DHIS2**. In such case one can resort to the [{readepi}](https://epiverse-trace.github.io/readepi/) package, which enables reading data from HIS APIs.  
-[TBC]

::::::::::::::::::::::::::::::::::::: keypoints 
- Use `{rio}, {io}, {readr}` and `{ImportExport}` to read data from individual files.
- Use {DBI}, {dplyr}, and {dbplyr} to import data from RDBMS
- Use `{readepi}` to read data form HIS APIs and RDBMS.
::::::::::::::::::::::::::::::::::::::::::::::::
